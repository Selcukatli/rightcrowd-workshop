/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/

// This file was generated by BAML: please do not edit it. Instead, edit the
// BAML files and re-generate this code using: baml-cli generate
// You can install baml-cli with:
//  $ npm install @boundaryml/baml
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code

const fileMap = {
  
  "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\n// Using the new OpenAI Responses API for enhanced formatting\nclient<llm> CustomGPT5 {\n  provider openai-responses\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT5Mini {\n  provider openai-responses\n  retry_policy Exponential\n  options {\n    model \"gpt-5-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Openai with chat completion\nclient<llm> CustomGPT5Chat {\n  provider openai\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Latest Anthropic Claude 4 models\nclient<llm> CustomOpus4 {\n  provider anthropic\n  options {\n    model \"claude-opus-4-1-20250805\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet4 {\n  provider anthropic\n  options {\n    model \"claude-sonnet-4-20250514\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-5-haiku-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// Example Google AI client (uncomment to use)\n// client<llm> CustomGemini {\n//   provider google-ai\n//   options {\n//     model \"gemini-2.5-pro\"\n//     api_key env.GOOGLE_API_KEY\n//   }\n// }\n\n// Example AWS Bedrock client (uncomment to use)\n// client<llm> CustomBedrock {\n//   provider aws-bedrock\n//   options {\n//     model \"anthropic.claude-sonnet-4-20250514-v1:0\"\n//     region \"us-east-1\"\n//     // AWS credentials are auto-detected from env vars\n//   }\n// }\n\n// Example Azure OpenAI client (uncomment to use)\n// client<llm> CustomAzure {\n//   provider azure-openai\n//   options {\n//     model \"gpt-5\"\n//     api_key env.AZURE_OPENAI_API_KEY\n//     base_url \"https://MY_RESOURCE_NAME.openai.azure.com/openai/deployments/MY_DEPLOYMENT_ID\"\n//     api_version \"2024-10-01-preview\"\n//   }\n// }\n\n// Example Vertex AI client (uncomment to use)\n// client<llm> CustomVertex {\n//   provider vertex-ai\n//   options {\n//     model \"gemini-2.5-pro\"\n//     location \"us-central1\"\n//     // Uses Google Cloud Application Default Credentials\n//   }\n// }\n\n// Example Ollama client for local models (uncomment to use)\n// client<llm> CustomOllama {\n//   provider openai-generic\n//   options {\n//     base_url \"http://localhost:11434/v1\"\n//     model \"llama4\"\n//     default_role \"user\" // Most local models prefer the user role\n//     // No API key needed for local Ollama\n//   }\n// }\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT5Mini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT5Mini, CustomGPT5]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
  "functions.baml": "// Functions for presentation generation\n\nfunction ParseOutline(outline: string, brandGuideline: BrandGuideline?) -> SlideSpec[] {\n  client CustomSonnet4\n  prompt #\"\n    Parse this presentation outline into individual slides.\n\n    For each section or major point in the outline, create a slide specification with:\n    - A clear, concise title\n    - Key points (bullet list of main ideas)\n    - A suggested visual description\n\n    OUTLINE:\n    {{ outline }}\n\n    {% if brandGuideline %}\n    BRAND VOICE: {{ brandGuideline.toneOfVoice }}\n    {% endif %}\n\n    Return a list of slide specifications. Each slide should be focused on ONE main topic.\n    Aim for 1-3 key points per slide for clarity.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction GenerateSlideContent(\n  slideSpec: SlideSpec,\n  brandGuideline: BrandGuideline?,\n  presentationContext: string\n) -> SlideContent {\n  client CustomSonnet4\n  prompt #\"\n    Generate polished presentation slide content.\n\n    SLIDE SPECIFICATION:\n    Title: {{ slideSpec.title }}\n    Key Points:\n    {% for point in slideSpec.keyPoints %}\n    - {{ point }}\n    {% endfor %}\n    Suggested Visual: {{ slideSpec.suggestedVisual }}\n\n    PRESENTATION CONTEXT:\n    {{ presentationContext }}\n\n    {% if brandGuideline %}\n    BRAND GUIDELINES:\n    - Tone: {{ brandGuideline.toneOfVoice }}\n    - Primary Color: {{ brandGuideline.primaryColor }}\n    - Secondary Color: {{ brandGuideline.secondaryColor }}\n    {% endif %}\n\n    Generate:\n    1. A polished slide title (can refine the original)\n    2. Concise, presentation-ready content (use bullet points, keep it scannable)\n    3. Speaker notes for the presenter\n    4. A detailed image prompt that would create a compelling visual for this slide\n\n    The image prompt should be specific and detailed, suitable for an AI image generator.\n    Consider the brand colors and style in the image prompt.\n\n    {{ ctx.output_format }}\n  \"#\n}\n\nfunction GenerateImagePrompt(\n  slideTitle: string,\n  slideContent: string,\n  brandGuideline: BrandGuideline?\n) -> string {\n  client CustomHaiku\n  prompt #\"\n    Create a detailed image generation prompt for a presentation slide.\n\n    SLIDE TITLE: {{ slideTitle }}\n    SLIDE CONTENT: {{ slideContent }}\n\n    {% if brandGuideline %}\n    BRAND STYLE:\n    - Colors: {{ brandGuideline.primaryColor }}, {{ brandGuideline.secondaryColor }}\n    - Style: {{ brandGuideline.styleDescription }}\n    {% endif %}\n\n    Generate a detailed prompt for an AI image generator (like Stable Diffusion or DALL-E).\n    The image should:\n    - Be professional and suitable for a business presentation\n    - Complement the slide content without being too literal\n    - Use the brand colors if specified\n    - Be clean and modern\n\n    Return ONLY the image prompt, nothing else.\n  \"#\n}\n",
  "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"typescript\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../app\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.213.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode async\n}\n",
  "types.baml": "// Types for presentation generation\n\nclass BrandGuideline {\n  name string\n  toneOfVoice string?\n  primaryColor string?\n  secondaryColor string?\n  styleDescription string?\n}\n\nclass SlideSpec {\n  title string\n  keyPoints string[] @description(\"Main points to cover on this slide\")\n  suggestedVisual string? @description(\"Description of what visual would work well\")\n}\n\nclass SlideContent {\n  title string\n  content string @description(\"Concise, presentation-ready content\")\n  speakerNotes string? @description(\"Notes for the presenter\")\n  imagePrompt string @description(\"Detailed prompt for image generation\")\n}\n",
}
export const getBamlFiles = () => {
    return fileMap;
}